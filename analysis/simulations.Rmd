---
title: "Simulations"
site: workflowr::wflow_site
output:
  workflowr::wflow_html:
    toc: false
editor_options:
  chunk_output_type: console
---

```{r packages, echo=FALSE}
library("DiagrammeR")
library("ggplot2")
library("ggpubr")

# colorblind-friendly palette
cbPalette <- c("#88CCEE", "#CC6677", "#DDCC77", "#117733", "#332288", "#AA4499", 
               "#44AA99", "#999933", "#882255", "#661100", "#6699CC", "#888888", "#000000")
```

```{r plotcode, echo=FALSE}
# Code for plots of simulation results
group_barchart = function(dirname, prefix='all_res_', n_x_show = 8, thresh = 0.05, pip_thresh = 0.5, methods=c()) {
  method_labels = c()
  beta_labels = c()
  all_pos_rates = c()
  
  for(m in methods) {
    fname = paste0(dirname, prefix, m, '.txt')
    res = na.omit(read.table(fname))
    num_cols = dim(res)[2]
    if(grepl('susie', m) || grepl('zuber', m)) {
      num_betas = num_cols 
    } else {
      num_betas = num_cols / 3
    }
    # compute rates of (true or false) positives
    for (i in 1:n_x_show) {
      if(grepl('susie', m) || grepl('zuber', m)) {
        posrate = sum(res[,i] >= pip_thresh) / length(res[,i])
      } else {
        posrate = sum(res[,(i+num_betas*2)] <= thresh) / length(res[,(i+num_betas*2)])
      }
      method_labels = c(method_labels, m)
      beta_labels = c(beta_labels, as.character(i))
      all_pos_rates = c(all_pos_rates, posrate)
    }
  }
  
  data = data.frame(method_labels, beta_labels, all_pos_rates)
  ggplot(data, aes(fill=method_labels, y=all_pos_rates, x=beta_labels)) +
    geom_bar(position="dodge", stat="identity") + 
    geom_hline(yintercept=0.05, linetype="dashed", color = "black") +
    scale_fill_manual(values=cbPalette) + theme(text = element_text(size = 20)) + 
    xlab('Exposures') + ylab('Positive Rate') + labs(fill = "Method") + ylim(0, 1)
}


power_fpr_thresh_plot = function(dirname, truevars, prefix='all_res_', n_x_show = 4, thresh = 0.05, methods=c()) {
  method_labels = c()
  beta_labels = c()
  all_pos_rates = c()
  truevars = as.numeric(unlist(strsplit(truevars, ",")))
  
  for(m in methods) {
    fname = paste0(dirname, prefix, m, '.txt')
    res = na.omit(read.table(fname))
    num_sims = dim(res)[1]
    num_cols = dim(res)[2]
    if(grepl('susie', m) || grepl('zuber', m)) {
      num_betas = num_cols
    } else {
      num_betas = num_cols / 3
    }
    num_falsevars = num_betas - length(truevars)
    tot_false = num_sims * num_falsevars
    falselim = tot_false * thresh
    
    # determine power of each true variable at specified FPR threshold
    sorted_pvals = c()
    for(row in 1:num_sims) {
      for(col in 1:num_betas) {
        if(grepl('susie', m) || grepl('zuber', m)) {
          entry = res[row,col]
        } else {
          entry = res[row,(2*num_betas+col)]
        }
        sorted_pvals = rbind(sorted_pvals, c(entry, col))
      }
    }
    if(grepl('susie', m) || grepl('zuber', m)) {
      sorted_pvals = sorted_pvals[order(sorted_pvals[,1],decreasing=TRUE),]
    } else {
      sorted_pvals = sorted_pvals[order(sorted_pvals[,1],decreasing=FALSE),]
    }

    truepos = rep(0, num_betas)
    falsepos = 0
    for(row in 1:dim(sorted_pvals)[1]) {
      var = sorted_pvals[row,2]
      if(var %in% truevars) {
        truepos[var] = truepos[var] + 1
      } else{
        falsepos = falsepos + 1
      }
      if(falsepos >= falselim) {
        break
      }
    }
    truepos = (truepos / num_sims)[1:n_x_show]
    for(i in 1:length(truepos)) {
      method_labels = c(method_labels, m)
      beta_labels = c(beta_labels, as.character(i))
      all_pos_rates = c(all_pos_rates, truepos[i])
    }
  }
  
  data = data.frame(method_labels, beta_labels, all_pos_rates)
  ggplot(data, aes(fill=method_labels, y=all_pos_rates, x=beta_labels)) +
    geom_bar(position="dodge", stat="identity") + 
    geom_hline(yintercept=0.05, linetype="dashed", color = "black") +
    scale_fill_manual(values=cbPalette) + theme(text = element_text(size = 20)) + 
    xlab('Exposures') + ylab(paste0('Power @ FPR = ', thresh)) + labs(fill = "Method") + ylim(0, 1)
}


param_lineplot = function(dirvec, param_name, param_vals, truepos, prefix='all_res_', 
                          thresh = 0.05, pip_thresh = 0.1, methods=c()) {
  all_method_labels = c()
  all_param_vals = c()
  all_fpr = c()
  all_power = c()

  for(i in 1:length(dirvec)) {
    dirname = dirvec[i]
    thisval = param_vals[i]
    for(m in methods) {
      fpr = 0
      power = 0
      fname = paste0(dirname, prefix, m, '.txt')
      res = na.omit(read.table(fname))
      num_cols = dim(res)[2]
      if(grepl('susie', m) || grepl('zuber', m)) {
        num_betas = num_cols 
      } else {
        num_betas = num_cols / 3
      }
      # compute rates of (true or false) positives
      for (i in 1:num_betas) {
        if(grepl('susie', m) || grepl('zuber', m)) {
          posrate = sum(res[,i] >= pip_thresh) / length(res[,i])
        } else {
          posrate = sum(res[,(i+num_betas*2)] <= thresh) / length(res[,(i+num_betas*2)])
        }
        if(i %in% truepos) {
          power = power + posrate
        } else {
          fpr = fpr + posrate
        }
      }
      power = power / length(truepos)
      fpr = fpr / (num_betas - length(truepos))
      all_method_labels = c(all_method_labels, m)
      all_param_vals = c(all_param_vals, thisval)
      all_power = c(all_power, power)
      all_fpr = c(all_fpr, fpr)
    }
  }
  
  data_fpr = data.frame(all_method_labels, all_param_vals, all_fpr)
  data_power = data.frame(all_method_labels, all_param_vals, all_power)
  fpr_plot = ggplot(data_fpr, 
    aes(group=all_method_labels, color=all_method_labels, y=all_fpr, x=all_param_vals)) +
    geom_line(linewidth=2) + geom_point(size=4) + 
    geom_hline(yintercept=0.05, linetype="dashed", color = "black") +
    scale_fill_manual(values=cbPalette) + theme(text = element_text(size = 20)) + 
    xlab(param_name) + ylab('False Positive Rate') + labs(fill = "Method") + ylim(0, 1)
  power_plot = ggplot(data_power, 
    aes(group=all_method_labels, color=all_method_labels, y=all_power, x=all_param_vals)) +
    geom_line(linewidth=2) + geom_point(size=4) + 
    scale_fill_manual(values=cbPalette) + theme(text = element_text(size = 20)) + 
    xlab(param_name) + ylab('Power') + labs(fill = "Method") + ylim(0, 1)
  ggarrange(fpr_plot, power_plot, nrow=1, ncol=2, common.legend = TRUE, legend="bottom")
}
```


### Simulation description

We simulate according to the following DAG:

```{r dag, echo=FALSE}
DiagrammeR::grViz("digraph {
  graph [layout = dot, rankdir = LR]

  node [shape = circle]
  G [label = 'G']
  Z [label = 'Z']
  X [label = 'X']
  Y [label = 'Y']

  # edge definitions with the node IDs
  edge []
  G -> X [label=<\U03B8<FONT POINT-SIZE='8'><SUB>GX</SUB></FONT>>]
  G -> Y [label=<\U03B8<FONT POINT-SIZE='8'><SUB>GY</SUB></FONT>>]
  G -> Z [label=<\U03B8<FONT POINT-SIZE='8'><SUB>GZ</SUB></FONT>>]
  X -> Z [dir=back; label=<\U03B8<FONT POINT-SIZE='8'><SUB>ZX</SUB></FONT>>]
  Z -> Y [label=<\U03B8<FONT POINT-SIZE='8'><SUB>ZY</SUB></FONT>>]
  X -> Y [label=<\U03B8<FONT POINT-SIZE='8'><SUB>XY</SUB></FONT>>]
  }",
  height = 350, width = 800)
```

<!-- ![](../figs/mvmr_dag.jpg) -->

Here, G are the Genotypes, X are the exposure phenotypes, Y is the outcome phenotype, and Z are confounders.
All except Y are expected to be multivariate. 
The edge variables signify effects between these variables.
Let $M$ be the number of SNPs, $K$ be the number of exposures, and $J$ be the number of confounders.

The structural equation model for this DAG is:

$$Z = G\theta_{GZ} + \epsilon_Z$$
$$X = G\theta_{GX} + Z\theta_{ZX} + \epsilon_X$$
$$Y = X\theta_{XY} + G\theta_{GY} + Z\theta_{ZY} + \epsilon_Y$$

G is assumed fixed or is drawn from standard normal distributions. Define

$$\psi_X = \theta_{GZ} * \theta_{ZX}$$
$$\psi_Y = \theta_{GZ} * \theta_{ZY}$$
Then $\psi_X$ defines the heritability of X mediated through Z, 
$\psi_Y$ defines the confounding effect from G to Y that is correlated with X,
and $\theta_{GY}$ defines the confounding effect from G to Y that is not correlated with X.

By default, $\theta_{XY}$ are fixed effects specified by the user, 
which allows control over the strength of effects in the simulation.
All other effects $theta_i$ (where $i$ is a stand-in for $GX$, $GY$, and so on) are drawn according to point-(multivarite-)normal distributions,

$$\theta_i = f_i * \gamma^*_{i},$$

where f is the point-(multivariate-)normal,

$$f_i \sim \pi_{0,i}\delta + \pi_{1,i}\mathcal{N}_d(\mu, \Sigma_{i}),$$

where $\delta$ is the Dirac delta function and $d$ is the dimensionality of the effected variable, i.e. $J$ if the effect is on $Z$, $K$ for $X$, or $1$ for $Y$. 
$\mu$, the mean parameter, is set to 0 by default, but can be set to non-zero values to allow “directional pleiotropy”. 
$\Sigma_i$ is currently taken to be a diagonal matrix, but could be generalized to allow correlated effects.

$\pi_{0,i}$ represents the amount of sparsity while $\pi_{1,i}$ represents the density, and $\pi_{0,i} + \pi_{1,i} = 1$. 
In practice this is achieved by first simulating the multivariate normal, then multiplying each entry by $\pi_{1,i}$, which is drawn separately for each entry according to

$$\pi_{1,i} \sim Bernoulli(\phi_i),$$

where $\phi_i$ is a parameter that controls the level of density. By default, the density of $\theta_{ZY}$ is set to 1 ($\phi_{ZY}=1$) because if some $Z_j$ does not affect $Y$ then it is not a confounder.

Finally, $\gamma_i$ represents the scaling parameter to achieve the desired $R^2$. $G$, $Z$, $X$, and $Y$ are controlled to have unit variance (see simulation of noise below). For $G$ to have the desired $R^2$ (heritability) on $Z$, $X$, or $Y$, we need to adjust this parameter by the number of SNPs and the sparsity of the effects. Therefore, the per-SNP $\gamma_i^*$ is 

$$\gamma^*_{i} = \sqrt{\gamma_{i} / M / \phi_i}$$

<!-- We draw alpha similarly to theta except that we do not allow sparsity, as a variable that does not affect Y is not a confounder, and a variable that does not affect X does not represent correlated horizontal pleiotropy. However, it may make sense to also allow sparsity for the effects of Z on X, as it could make sense for some Z to affect some subset of X. -->

The noise variances, epsilon, are designed so that Z, X, and Y have unit variance. So they are simulated according to

$$\epsilon_Z \sim \mathcal{N}_J(0, \xi_Z I_J)$$
$$\epsilon_X \sim \mathcal{N}_K(0, \xi_Z I_K)$$
$$\epsilon_Y \sim \mathcal{N}(0, \xi_Y)$$

where

$$\xi_Z = 1 - \gamma_{GZ}$$
$$\xi_X = 1 - \gamma_{GX} - \gamma_{ZX}$$
$$\xi_y = 1 - \gamma_{GY} - \gamma_{ZY} - \sum_i \theta_{XY,i}^2$$

### Baseline Methods Assessed

* "2SLS": vanilla two-stage least squares implemented by me. I first perform multiple regression of each $X_j$ on $G$, obtaining an estimate $\hat{\tilde{X}}$ of the genetic component of X, $\tilde{X}$. I then regress $Y$ on $\hat{\tilde{X}}$ (second-stage regression).

$$X_1,...,X_K \sim G \rightarrow \hat{\tilde{X}}$$
$$Y \sim \hat{\tilde{X}} \rightarrow \hat{\theta}_{XY}, pvalue$$

* "2SLS Oracle": This is an augmented version of 2SLS where, in the second-stage regression, I include the true values of $G\theta_{GZ}$ (which is equal to the genetic component of Z, $\tilde{Z}$) and $G\theta_{GY}$ as covariates. This represents the ideal performance of 2SLS if the true confounders were known ("oracle" setting), though it may be beatable by putting appropriate sparse priors on the confounders.

$$X_1,...,X_K \sim G \rightarrow \hat{\tilde{X}}$$
$$Y \sim \hat{\tilde{X}} + \tilde{Z} + G\theta_{GY} \rightarrow \hat{\theta}_{XY}, pvalue$$

* "2SLS Enhanced": This is an augmented version of 2SLS where, in the second stage regression, I include estimates of $G\theta_{GZ}$ and $G\theta_{GY}$ that can be obtained without knowing the true values. The former is estimated by running SVD on $\hat{\theta}_{GX}$. The latter is estimated by regressing $X$ out of $Y$ and then regressing those residuals on $G$.

$$X_1,...,X_K \sim G \rightarrow \hat{\tilde{X}}$$

$$SVD(\hat{\theta}_{GX}) \rightarrow \widehat{\theta_{GZ}\theta_{ZX}} = \hat{\psi}_X$$
$$Y \sim X \rightarrow \hat{Y}_{resid}$$
$$\hat{Y}_{resid} \sim G \rightarrow \hat{\theta}_{GY}$$
$$Y \sim \hat{\tilde{X}} + G\hat{\psi}_x + G\hat{\theta}_{GY} \rightarrow \hat{\theta}_{XY}, pvalue$$


* SuSiE-SVD: This performs the same first-stage regression as 2SLS, then runs runs the SuSiE R package for the second-stage regression. Along with $\hat{\tilde{X}}$, we include the SNPs $G$ to attempt to control for uncorrelated pleiotropy as well as an estimate of the confounders $\hat{\tilde{Z}}$, produced by running truncated singular value decomposition (SVD) on $\hat{\tilde{X}}$, to attempt to control for correlated pleiotropy. We give a slightly incorrect value for the true number of confounders to SVD.

$$X_1,...,X_K \sim G \rightarrow \hat{\tilde{X}}$$
$$SVD(\hat{\tilde{X}}) \rightarrow \hat{\tilde{Z}} = G\hat{\theta}_{GZ}$$

$$susieR::susie(Y \sim \hat{\tilde{X}} + G + \hat{\tilde{Z}}) \rightarrow \hat{\theta}_{XY}, pvalue$$

* Multivariate versions of four standard MR methods, implemented in the MendelianRandomization package: IVW, Egger, Median, and Lasso. For each of these, I first regress each $X_j$ and $Y$ on each genetic variant. The betas and standard errors from these per-variant regressions (mimicking summary statistics) are given to the methods as input.

$$X_i \sim G_j \rightarrow \hat{\beta}_{ij}, \hat{s}^2_{ij} \qquad Y \sim G_j \rightarrow \hat{\beta}_{yj}, \hat{s}^2_{yj}$$
$$MendelianRandomization::MVMR\_IVW(\hat{\beta}, \hat{s}^2) \rightarrow \hat{\theta}_{XY}, pvalue$$



### Simulation Results

Here are some plots showing our simulation results. First, I'll briefly explain the parameter settings.

The following parameters are fixed:

* N = 20000 samples / individuals
* M = 100 SNPs
* K = 30 exposures / risk factors
* First four exposures are true effects with $\theta_{XY}$ = 0.05 / 0.1 / 0.2 / 0.3.
    This means that the variance explained of the outcome is 0.0025, 0.01, 0.04, 0.09.
    The other 26 effects are null. I show the first four nulls in the bar plots below for illustrative purposes.
* J = 3 correlated confounding variables "Z"
* 50% sparsity, i.e. of genotype effects on X/Y/Z are set to zero. The rest are drawn from normal distributions.
    In other words, the effects are point-normal. See "About" for details.

There are five key parameters I vary in these simulations:

* $\gamma_{GZ}$/$\gamma_{GY}$/$\gamma_{GZ}$ = variance of X/Y/Z explained by G; 
* $\psi_{X}$/$\psi_{Y}$ = percent of X/Y explained by G through confounder Z;
* $\mu$ = mean parameter of multivariate normal effect size draws

The default settings of these are 0.1 (10%) for $\gamma_{GZ}$/$\gamma_{GY}$/$\psi_{X}$/$\psi_{Y}$ and 0 for $\mu$.
The default setting for $\gamma_{GZ}$ is 0.6, which is high, but this is to allow a wide range of $\psi_{X}$ and $\psi_{Y}$
values, since $\psi_{X}$ and $\psi_{Y}$ cannot be greater than $\gamma_{GZ}$.


I show two types of plots:

* Bar plots, showing results for a single parameter setting, with Positive Rate (FPR/Power) on the y-axis and the index of the exposure on the x-axis. The first four exposures are true positives (so y-axis is empirical power) while the rest are null (so y-axis is FPR); only the first four nulls are shown for brevity.
* Line plots, showing results as one of the parameters is varied. FPR plots show results averaged over the four true effects while Power plots show results averaged over the null effects. FPR/Power is on the y-axis and the parameter value is on the x-axis.



Here are the results with the default settings. We see that all methods except 2SLS-Oracle are inflated, with 2SLS-Oracle being the most powerful. Apart from 2SLS-Oracle, there is a clear order among the other methods in terms of both FPR and Power, with 2SLS > MVMR Lasso > MVMR Median > MVMR IVW/Egger.

```{r both_plei, echo=FALSE, fig.width=12}
group_barchart('data/results/both_plei_gx_0.1_gy_0.1_gz_0.6_psix_0.1_psiy_0.1_mu_0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls', '2sls_oracle', 'ivw', 'egger', 'median', 'lasso'))
```



As a sanity check, the plot below shows results in simulations with no confounding. As expected, all methods perform well.

```{r no_plei, echo=FALSE, fig.width=12}
group_barchart('data/results/no_plei_gx_0.1_gy_0.1_gz_0.6_psix_0.1_psiy_0.1_mu_0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls', '2sls_oracle', 'ivw', 'egger', 'median', 'lasso'))
```


Here's the performance with only correlated pleiotropy. Here we see that all methods except the oracle method have inflated FPR:

```{r cor_plei, echo=FALSE, fig.width=12}
group_barchart('data/results/cor_plei_gx_0.1_gy_0.1_gz_0.6_psix_0.1_psiy_0.1_mu_0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls', '2sls_oracle', 'ivw', 'egger', 'median', 'lasso'))
```

Finally, here's the performance with only uncorrelated pleiotropy.

```{r uncor_plei, echo=FALSE, fig.width=12}
group_barchart('data/results/uncor_plei_gx_0.1_gy_0.1_gz_0.6_psix_0.1_psiy_0.1_mu_0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls', '2sls_oracle', 'ivw', 'egger', 'median', 'lasso'))
```



    
    
    
### Simulations with new settings + Cate, RPCA, & GFA plugins

I performed some more simulations under settings that may be more realistic.
The following changes were made as compared with the above simulations:

<!-- * The number of samples was increased from 20,000 to 50,000 -->
<!-- * As a result of the parameter changes, some of the values they varied between were changed. -->
* The number of SNPs was increased from 100 to 300
* The density parameters were decreased from $\phi_X=\phi_Y=\phi_Z=50\%$ to $\phi_X=10\%, \phi_Y=\phi_Z=10\%$; thus a much smaller percentage of variants will affect the phenotypes, especially for pleiotropic effects. 
* The defaults for $\theta_{GX}$ and $\theta_{GY}$ were increased from $0.1$ to $0.2$.
  Meanwhile the default for $\theta_{GZ}$ was decreased to $0.4$ and $\psi_Y$ was kept at $0.15$.
  This was done to obtain more balanced and realistic heritabilities, something like we might expect
    if $X$ were lipid measurements and $Y$ was some complex trait.
  The resulting heritabilities are $h^2(X)=30\%$, $h^2(Z)=40\%$, $h^2(Y)=49.25\%$.
* I didn't bother fiddling with $\theta_{GX}$ or $\mu$ here as the effects should be similar.
* I now include more methods in the plots.


Here I'm comparing standard methods augmented with either Cate or RPCA,
under several sparsity and SNP count settings.
(Update: I have now added GFA as well, which also works on summary statistics.)
This will show that Cate is more robust than RPCA in that it does not assume
that the G-->Z effects are dense, while RPCA needs this assumption.
Of course, the benefit of RPCA is we can apply it to summary statistics,
while Cate needs individual-level data.

We will also see that Robust generally enjoys greater power than SuSiE,
but is occasionally inflated, particularly in a scenario with denser direct effects
and fewer SNPs overall. 
On the other hand, SuSiE has low power to detect weak effects but is very robust
to almost any setting, provided that it is given a reasonable estimate of 
correlated pleiotropic effects via Cate or RPCA.

Here are the results with correlated pleiotropy only, with $\theta_{gx}$ sparse
and $\theta_{gz}$ dense ($\phi_{gx}=0.1$ and $\phi_{gz}=0.8$).

```{r cor_plei_gfa1, echo=FALSE, fig.width=12}
group_barchart('data/results_gfa_rpca1/cor_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls_oracle', 'ivw', 'ivw_cate', 'ivw_rpca', 'ivw_gfa',
                         # 'robust', 'robust_cate', 'robust_rpca', 'robust_gfa', 
                         'susie', 'susie_cate', 'susie_rpca', 'susie_gfa'))
```

Here's the same plot, except with $\phi_{gz}=0.1$. This is a problem for RPCA,
but not Cate.

```{r cor_plei_gfa2, echo=FALSE, fig.width=12}
group_barchart('data/results_gfa_rpca2/cor_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls_oracle', 'ivw', 'ivw_cate', 'ivw_rpca', 'ivw_gfa',
                         # 'robust', 'robust_cate', 'robust_rpca', 'robust_gfa', 
                         'susie', 'susie_cate', 'susie_rpca', 'susie_gfa'))
```

Finally, here's a setting with $100$ SNPs (the above two have 300) and $\phi_{gx}=0.5$.

```{r cor_plei_gfa4, echo=FALSE, fig.width=12}
group_barchart('data/results_gfa_rpca4/cor_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls_oracle', 'ivw', 'ivw_cate', 'ivw_rpca', 'ivw_gfa',
                         # 'robust', 'robust_cate', 'robust_rpca', 'robust_gfa', 
                         'susie', 'susie_cate', 'susie_rpca', 'susie_gfa'))
```

Here's the same, but with both kinds of pleiotropy:

```{r both_plei_gfa4, echo=FALSE, fig.width=12}
group_barchart('data/results_gfa_rpca4/both_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls_oracle', 'ivw', 'ivw_cate', 'ivw_rpca', 'ivw_gfa',
                         # 'robust', 'robust_cate', 'robust_rpca', 'robust_gfa', 
                         'susie', 'susie_cate', 'susie_rpca', 'susie_gfa'))
```

Finally, here's the power at a fixed FPR threshold, using the same data as above:

```{r powfpr_both_plei_gfa4, echo=FALSE, fig.width=12}
power_fpr_thresh_plot('data/results_gfa_rpca4/both_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/', 
                      c('1','2','3','4'), prefix='all_res_', n_x_show = 4, thresh = 0.05,
               methods=c('2sls_oracle', 'ivw', 'ivw_cate', 'ivw_rpca', 'ivw_gfa',
                         # 'robust', 'robust_cate', 'robust_rpca', 'robust_gfa', 
                         'susie', 'susie_cate', 'susie_rpca', 'susie_gfa'))
```

