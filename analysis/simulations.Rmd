---
title: "Simulations"
site: workflowr::wflow_site
output:
  workflowr::wflow_html:
    toc: false
editor_options:
  chunk_output_type: console
---

```{r packages, echo=FALSE}
library("DiagrammeR")
library("ggplot2")
library("ggpubr")

# colorblind-friendly palette
cbPalette <- c("#88CCEE", "#CC6677", "#DDCC77", "#117733", "#332288", "#AA4499", 
               "#44AA99", "#999933", "#882255", "#661100", "#6699CC", "#888888", "#000000")
```

```{r plotcode, echo=FALSE}
# check if this is a pip method
pip_checker = function(method) {
  return(grepl('susie', method) || grepl('mrash', method) || grepl('zuber', method) || grepl('brms', method))
}

# Code for plots of simulation results
group_barchart = function(dirname, prefix='all_res_', n_x_show = 8, thresh = 0.05, pip_thresh = 0.95, methods=c()) {
  method_labels = c()
  beta_labels = c()
  all_pos_rates = c()
  
  for(m in methods) {
    fname = paste0(dirname, prefix, m, '.txt')
    res = na.omit(read.table(fname))
    num_cols = dim(res)[2]
    ss = strsplit(m, '_')[[1]][1]  # isolate the second-stage method name
    if(pip_checker(ss)) {
      num_betas = num_cols 
    } else {
      num_betas = num_cols / 3
    }
    # compute rates of (true or false) positives
    for (i in 1:n_x_show) {
      if(pip_checker(ss)) {
        posrate = sum(res[,i] >= pip_thresh) / length(res[,i])
      } else {
        posrate = sum(res[,(i+num_betas*2)] <= thresh) / length(res[,(i+num_betas*2)])
      }
      method_labels = c(method_labels, m)
      beta_labels = c(beta_labels, as.character(i))
      all_pos_rates = c(all_pos_rates, posrate)
    }
  }
  
  data = data.frame(method_labels, beta_labels, all_pos_rates)
  ggplot(data, aes(fill=method_labels, y=all_pos_rates, x=beta_labels)) +
    geom_bar(position="dodge", stat="identity") + 
    geom_hline(yintercept=0.05, linetype="dashed", color = "black") +
    scale_fill_manual(values=cbPalette) + theme(text = element_text(size = 20)) + 
    xlab('Exposures') + ylab('Positive Rate') + labs(fill = "Method") + ylim(0, 1)
}


power_fpr_thresh_plot = function(dirname, truevars, prefix='all_res_', n_x_show = 4, thresh = 0.05, methods=c()) {
  method_labels = c()
  beta_labels = c()
  all_pos_rates = c()
  truevars = as.numeric(unlist(strsplit(truevars, ",")))
  
  for(m in methods) {
    fname = paste0(dirname, prefix, m, '.txt')
    res = na.omit(read.table(fname))
    num_sims = dim(res)[1]
    num_cols = dim(res)[2]
    ss = strsplit(m, '_')[[1]][1]  # isolate the second-stage method name
    if(pip_checker(ss)) {
      num_betas = num_cols
    } else {
      num_betas = num_cols / 3
    }
    num_falsevars = num_betas - length(truevars)
    tot_false = num_sims * num_falsevars
    falselim = tot_false * thresh
    
    # determine power of each true variable at specified FPR threshold
    sorted_pvals = c()
    for(row in 1:num_sims) {
      for(col in 1:num_betas) {
        if(pip_checker(ss)) {
          entry = res[row,col]
        } else {
          entry = res[row,(2*num_betas+col)]
        }
        sorted_pvals = rbind(sorted_pvals, c(entry, col))
      }
    }
    if(pip_checker(ss)) {
      sorted_pvals = sorted_pvals[order(sorted_pvals[,1],decreasing=TRUE),]
    } else {
      sorted_pvals = sorted_pvals[order(sorted_pvals[,1],decreasing=FALSE),]
    }

    truepos = rep(0, num_betas)
    falsepos = 0
    for(row in 1:dim(sorted_pvals)[1]) {
      var = sorted_pvals[row,2]
      if(var %in% truevars) {
        truepos[var] = truepos[var] + 1
      } else{
        falsepos = falsepos + 1
      }
      if(falsepos >= falselim) {
        break
      }
    }
    truepos = (truepos / num_sims)[1:n_x_show]
    for(i in 1:length(truepos)) {
      method_labels = c(method_labels, m)
      beta_labels = c(beta_labels, as.character(i))
      all_pos_rates = c(all_pos_rates, truepos[i])
    }
  }
  
  data = data.frame(method_labels, beta_labels, all_pos_rates)
  ggplot(data, aes(fill=method_labels, y=all_pos_rates, x=beta_labels)) +
    geom_bar(position="dodge", stat="identity") + 
    geom_hline(yintercept=0.05, linetype="dashed", color = "black") +
    scale_fill_manual(values=cbPalette) + theme(text = element_text(size = 20)) + 
    xlab('Exposures') + ylab(paste0('Power @ FPR = ', thresh)) + labs(fill = "Method") + ylim(0, 1)
}


param_lineplot = function(dirvec, param_name, param_vals, truepos, prefix='all_res_', 
                          thresh = 0.05, pip_thresh = 0.95, methods=c()) {
  all_method_labels = c()
  all_param_vals = c()
  all_fpr = c()
  all_power = c()

  for(i in 1:length(dirvec)) {
    dirname = dirvec[i]
    thisval = param_vals[i]
    for(m in methods) {
      fpr = 0
      power = 0
      fname = paste0(dirname, prefix, m, '.txt')
      res = na.omit(read.table(fname))
      num_cols = dim(res)[2]
      ss = strsplit(m, '_')[[1]][1]  # isolate the second-stage method name
      if(pip_checker(ss)) {
        num_betas = num_cols 
      } else {
        num_betas = num_cols / 3
      }
      # compute rates of (true or false) positives
      for (i in 1:num_betas) {
        if(pip_checker(ss)) {
          posrate = sum(res[,i] >= pip_thresh) / length(res[,i])
        } else {
          posrate = sum(res[,(i+num_betas*2)] <= thresh) / length(res[,(i+num_betas*2)])
        }
        if(i %in% truepos) {
          power = power + posrate
        } else {
          fpr = fpr + posrate
        }
      }
      power = power / length(truepos)
      fpr = fpr / (num_betas - length(truepos))
      all_method_labels = c(all_method_labels, m)
      all_param_vals = c(all_param_vals, thisval)
      all_power = c(all_power, power)
      all_fpr = c(all_fpr, fpr)
    }
  }
  
  data_fpr = data.frame(all_method_labels, all_param_vals, all_fpr)
  data_power = data.frame(all_method_labels, all_param_vals, all_power)
  fpr_plot = ggplot(data_fpr, 
    aes(group=all_method_labels, color=all_method_labels, y=all_fpr, x=all_param_vals)) +
    geom_line(linewidth=2) + geom_point(size=4) + 
    geom_hline(yintercept=0.05, linetype="dashed", color = "black") +
    scale_fill_manual(values=cbPalette) + theme(text = element_text(size = 20)) + 
    xlab(param_name) + ylab('False Positive Rate') + labs(fill = "Method") + ylim(0, 1)
  power_plot = ggplot(data_power, 
    aes(group=all_method_labels, color=all_method_labels, y=all_power, x=all_param_vals)) +
    geom_line(linewidth=2) + geom_point(size=4) + 
    scale_fill_manual(values=cbPalette) + theme(text = element_text(size = 20)) + 
    xlab(param_name) + ylab('Power') + labs(fill = "Method") + ylim(0, 1)
  ggarrange(fpr_plot, power_plot, nrow=1, ncol=2, common.legend = TRUE, legend="bottom")
}
```


## Simulation description

We simulate according to the following DAG:

```{r dag, echo=FALSE}
DiagrammeR::grViz("digraph {
  graph [layout = dot, rankdir = LR]

  node [shape = circle]
  G [label = 'G']
  Z [label = 'Z']
  X [label = 'X']
  Y [label = 'Y']

  # edge definitions with the node IDs
  edge []
  G -> X [label=<\U03B8<FONT POINT-SIZE='8'><SUB>GX</SUB></FONT>>]
  G -> Y [label=<\U03B8<FONT POINT-SIZE='8'><SUB>GY</SUB></FONT>>]
  G -> Z [label=<\U03B8<FONT POINT-SIZE='8'><SUB>GZ</SUB></FONT>>]
  X -> Z [dir=back; label=<\U03B8<FONT POINT-SIZE='8'><SUB>ZX</SUB></FONT>>]
  Z -> Y [label=<\U03B8<FONT POINT-SIZE='8'><SUB>ZY</SUB></FONT>>]
  X -> Y [label=<\U03B8<FONT POINT-SIZE='8'><SUB>XY</SUB></FONT>>]
  }",
  height = 350, width = 800)
```

<!-- ![](../figs/mvmr_dag.jpg) -->

Here, G are the Genotypes, X are the exposure phenotypes, Y is the outcome phenotype, and Z are confounders.
All except Y are expected to be multivariate. 
The edge variables signify effects between these variables.
Let $M$ be the number of SNPs, $K$ be the number of exposures, and $J$ be the number of confounders.

The structural equation model for this DAG is:

$$Z = G\theta_{GZ} + \epsilon_Z$$
$$X = G\theta_{GX} + Z\theta_{ZX} + \epsilon_X$$
$$Y = X\theta_{XY} + G\theta_{GY} + Z\theta_{ZY} + \epsilon_Y$$

G is assumed fixed or is drawn from standard normal distributions. Define

$$\psi_X = \theta_{GZ} * \theta_{ZX}$$
$$\psi_Y = \theta_{GZ} * \theta_{ZY}$$
Then $\psi_X$ defines the heritability of X mediated through Z, 
$\psi_Y$ defines the confounding effect from G to Y that is correlated with X,
and $\theta_{GY}$ defines the confounding effect from G to Y that is not correlated with X.

By default, $\theta_{XY}$ are fixed effects specified by the user, 
which allows control over the strength of effects in the simulation.
All other effects $theta_i$ (where $i$ is a stand-in for $GX$, $GY$, and so on) are drawn according to point-(multivarite-)normal distributions,

$$\theta_i = f_i * \gamma^*_{i},$$

where f is the point-(multivariate-)normal,

$$f_i \sim \pi_{0,i}\delta + \pi_{1,i}\mathcal{N}_d(\mu, \Sigma_{i}),$$

where $\delta$ is the Dirac delta function and $d$ is the dimensionality of the effected variable, i.e. $J$ if the effect is on $Z$, $K$ for $X$, or $1$ for $Y$. 
$\mu$, the mean parameter, is set to 0 by default, but can be set to non-zero values to allow “directional pleiotropy”. 
$\Sigma_i$ is currently taken to be a diagonal matrix, but could be generalized to allow correlated effects.

$\pi_{0,i}$ represents the amount of sparsity while $\pi_{1,i}$ represents the density, and $\pi_{0,i} + \pi_{1,i} = 1$. 
In practice this is achieved by first simulating the multivariate normal, then multiplying each entry by $\pi_{1,i}$, which is drawn separately for each entry according to

$$\pi_{1,i} \sim Bernoulli(\phi_i),$$

where $\phi_i$ is a parameter that controls the level of density. By default, the density of $\theta_{ZY}$ is set to 1 ($\phi_{ZY}=1$) because if some $Z_j$ does not affect $Y$ then it is not a confounder.

Finally, $\gamma_i$ represents the scaling parameter to achieve the desired $R^2$. $G$, $Z$, $X$, and $Y$ are controlled to have unit variance (see simulation of noise below). For $G$ to have the desired $R^2$ (heritability) on $Z$, $X$, or $Y$, we need to adjust this parameter by the number of SNPs and the sparsity of the effects. Therefore, the per-SNP $\gamma_i^*$ is 

$$\gamma^*_{i} = \sqrt{\gamma_{i} / M / \phi_i}$$

<!-- We draw alpha similarly to theta except that we do not allow sparsity, as a variable that does not affect Y is not a confounder, and a variable that does not affect X does not represent correlated horizontal pleiotropy. However, it may make sense to also allow sparsity for the effects of Z on X, as it could make sense for some Z to affect some subset of X. -->

The noise variances, epsilon, are designed so that Z, X, and Y have unit variance. So they are simulated according to

$$\epsilon_Z \sim \mathcal{N}_J(0, \xi_Z I_J)$$
$$\epsilon_X \sim \mathcal{N}_K(0, \xi_Z I_K)$$
$$\epsilon_Y \sim \mathcal{N}(0, \xi_Y)$$

where

$$\xi_Z = 1 - \gamma_{GZ}$$
$$\xi_X = 1 - \gamma_{GX} - \gamma_{ZX}$$
$$\xi_y = 1 - \gamma_{GY} - \gamma_{ZY} - \sum_i \theta_{XY,i}^2$$

### Baseline Methods Assessed

* "2SLS": vanilla two-stage least squares implemented by me. I first perform multiple regression of each $X_j$ on $G$, obtaining an estimate $\hat{\tilde{X}}$ of the genetic component of X, $\tilde{X}$. I then regress $Y$ on $\hat{\tilde{X}}$ (second-stage regression).

$$X_1,...,X_K \sim G \rightarrow \hat{\tilde{X}}$$
$$Y \sim \hat{\tilde{X}} \rightarrow \hat{\theta}_{XY}, pvalue$$

* "2SLS Oracle": This is an augmented version of 2SLS where, in the second-stage regression, I include the true values of $G\theta_{GZ}$ (which is equal to the genetic component of Z, $\tilde{Z}$) and $G\theta_{GY}$ as covariates. This represents the ideal performance of 2SLS if the true confounders were known ("oracle" setting), though it may be beatable by putting appropriate sparse priors on the confounders.

$$X_1,...,X_K \sim G \rightarrow \hat{\tilde{X}}$$
$$Y \sim \hat{\tilde{X}} + \tilde{Z} + G\theta_{GY} \rightarrow \hat{\theta}_{XY}, pvalue$$

* "2SLS Enhanced": This is an augmented version of 2SLS where, in the second stage regression, I include estimates of $G\theta_{GZ}$ and $G\theta_{GY}$ that can be obtained without knowing the true values. The former is estimated by running SVD on $\hat{\theta}_{GX}$. The latter is estimated by regressing $X$ out of $Y$ and then regressing those residuals on $G$.

$$X_1,...,X_K \sim G \rightarrow \hat{\tilde{X}}$$

$$SVD(\hat{\theta}_{GX}) \rightarrow \widehat{\theta_{GZ}\theta_{ZX}} = \hat{\psi}_X$$
$$Y \sim X \rightarrow \hat{Y}_{resid}$$
$$\hat{Y}_{resid} \sim G \rightarrow \hat{\theta}_{GY}$$
$$Y \sim \hat{\tilde{X}} + G\hat{\psi}_x + G\hat{\theta}_{GY} \rightarrow \hat{\theta}_{XY}, pvalue$$


* SuSiE-SVD: This performs the same first-stage regression as 2SLS, then runs runs the SuSiE R package for the second-stage regression. Along with $\hat{\tilde{X}}$, we include the SNPs $G$ to attempt to control for uncorrelated pleiotropy as well as an estimate of the confounders $\hat{\tilde{Z}}$, produced by running truncated singular value decomposition (SVD) on $\hat{\tilde{X}}$, to attempt to control for correlated pleiotropy. We give a slightly incorrect value for the true number of confounders to SVD.

$$X_1,...,X_K \sim G \rightarrow \hat{\tilde{X}}$$
$$SVD(\hat{\tilde{X}}) \rightarrow \hat{\tilde{Z}} = G\hat{\theta}_{GZ}$$

$$susieR::susie(Y \sim \hat{\tilde{X}} + G + \hat{\tilde{Z}}) \rightarrow \hat{\theta}_{XY}, pvalue$$

* Multivariate versions of four standard MR methods, implemented in the MendelianRandomization package: IVW, Egger, Median, and Lasso. For each of these, I first regress each $X_j$ and $Y$ on each genetic variant. The betas and standard errors from these per-variant regressions (mimicking summary statistics) are given to the methods as input.

$$X_i \sim G_j \rightarrow \hat{\beta}_{ij}, \hat{s}^2_{ij} \qquad Y \sim G_j \rightarrow \hat{\beta}_{yj}, \hat{s}^2_{yj}$$
$$MendelianRandomization::MVMR\_IVW(\hat{\beta}, \hat{s}^2) \rightarrow \hat{\theta}_{XY}, pvalue$$



## Simulation Results

Here are some plots showing our simulation results. First, I'll briefly explain the parameter settings.

The following parameters are fixed:

* N = 20000 samples / individuals
* M = 100 SNPs
* K = 30 exposures / risk factors
* First four exposures are true effects with $\theta_{XY}$ = 0.05 / 0.1 / 0.2 / 0.3.
    This means that the variance explained of the outcome is 0.0025, 0.01, 0.04, 0.09.
    The other 26 effects are null. I show the first four nulls in the bar plots below for illustrative purposes.
* J = 3 correlated confounding variables "Z"
* 50% sparsity, i.e. of genotype effects on X/Y/Z are set to zero. The rest are drawn from normal distributions.
    In other words, the effects are point-normal. See "About" for details.

There are five key parameters I vary in these simulations:

* $\gamma_{GZ}$/$\gamma_{GY}$/$\gamma_{GZ}$ = variance of X/Y/Z explained by G; 
* $\psi_{X}$/$\psi_{Y}$ = percent of X/Y explained by G through confounder Z;
* $\mu$ = mean parameter of multivariate normal effect size draws

The default settings of these are 0.1 (10%) for $\gamma_{GZ}$/$\gamma_{GY}$/$\psi_{X}$/$\psi_{Y}$ and 0 for $\mu$.
The default setting for $\gamma_{GZ}$ is 0.6, which is high, but this is to allow a wide range of $\psi_{X}$ and $\psi_{Y}$
values, since $\psi_{X}$ and $\psi_{Y}$ cannot be greater than $\gamma_{GZ}$.


I show two types of plots:

* Bar plots, showing results for a single parameter setting, with Positive Rate (FPR/Power) on the y-axis and the index of the exposure on the x-axis. The first four exposures are true positives (so y-axis is empirical power) while the rest are null (so y-axis is FPR); only the first four nulls are shown for brevity.
* Line plots, showing results as one of the parameters is varied. FPR plots show results averaged over the four true effects while Power plots show results averaged over the null effects. FPR/Power is on the y-axis and the parameter value is on the x-axis.



Here are the results with the default settings. We see that all methods except 2SLS-Oracle are inflated, with 2SLS-Oracle being the most powerful. Apart from 2SLS-Oracle, there is a clear order among the other methods in terms of both FPR and Power, with 2SLS > MVMR Lasso > MVMR Median > MVMR IVW/Egger.

```{r both_plei, echo=FALSE, fig.width=12}
group_barchart('data/results/both_plei_gx_0.1_gy_0.1_gz_0.6_psix_0.1_psiy_0.1_mu_0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls', '2sls_oracle', 'ivw', 'egger', 'median', 'lasso'))
```



As a sanity check, the plot below shows results in simulations with no confounding. As expected, all methods perform well.

```{r no_plei, echo=FALSE, fig.width=12}
group_barchart('data/results/no_plei_gx_0.1_gy_0.1_gz_0.6_psix_0.1_psiy_0.1_mu_0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls', '2sls_oracle', 'ivw', 'egger', 'median', 'lasso'))
```


Here's the performance with only correlated pleiotropy. Here we see that all methods except the oracle method have inflated FPR:

```{r cor_plei, echo=FALSE, fig.width=12}
group_barchart('data/results/cor_plei_gx_0.1_gy_0.1_gz_0.6_psix_0.1_psiy_0.1_mu_0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls', '2sls_oracle', 'ivw', 'egger', 'median', 'lasso'))
```

Finally, here's the performance with only uncorrelated pleiotropy.

```{r uncor_plei, echo=FALSE, fig.width=12}
group_barchart('data/results/uncor_plei_gx_0.1_gy_0.1_gz_0.6_psix_0.1_psiy_0.1_mu_0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls', '2sls_oracle', 'ivw', 'egger', 'median', 'lasso'))
```



    
    
    
## Simulations with new settings + Cate, RPCA, & GFA plugins

I performed some more simulations under settings that may be more realistic.
The following changes were made as compared with the above simulations:

<!-- * The number of samples was increased from 20,000 to 50,000 -->
<!-- * As a result of the parameter changes, some of the values they varied between were changed. -->
* The number of SNPs was increased from 100 to 300
* The density parameters were decreased from $\phi_X=\phi_Y=\phi_Z=50\%$ to $\phi_X=10\%, \phi_Y=\phi_Z=10\%$; thus a much smaller percentage of variants will affect the phenotypes, especially for pleiotropic effects. 
* The defaults for $\theta_{GX}$ and $\theta_{GY}$ were increased from $0.1$ to $0.2$.
  Meanwhile the default for $\theta_{GZ}$ was decreased to $0.4$ and $\psi_Y$ was kept at $0.15$.
  This was done to obtain more balanced and realistic heritabilities, something like we might expect
    if $X$ were lipid measurements and $Y$ was some complex trait.
  The resulting heritabilities are $h^2(X)=30\%$, $h^2(Z)=40\%$, $h^2(Y)=49.25\%$.
* I didn't bother fiddling with $\theta_{GX}$ or $\mu$ here as the effects should be similar.
* I now include more methods in the plots.


Here I'm comparing standard methods augmented with either Cate or RPCA,
under several sparsity and SNP count settings.
(Update: I have now added GFA as well, which also works on summary statistics.)
This will show that Cate is more robust than RPCA in that it does not assume
that the G-->Z effects are dense, while RPCA needs this assumption.
Of course, the benefit of RPCA is we can apply it to summary statistics,
while Cate needs individual-level data.

We will also see that Robust generally enjoys greater power than SuSiE,
but is occasionally inflated, particularly in a scenario with denser direct effects
and fewer SNPs overall. 
On the other hand, SuSiE has low power to detect weak effects but is very robust
to almost any setting, provided that it is given a reasonable estimate of 
correlated pleiotropic effects via Cate or RPCA.

Here are the results with correlated pleiotropy only, with $\theta_{gx}$ sparse
and $\theta_{gz}$ dense ($\phi_{gx}=0.1$ and $\phi_{gz}=0.8$).

```{r cor_plei_gfa1, echo=FALSE, fig.width=12}
group_barchart('data/results_gfa_rpca1/cor_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls_oracle', 'ivw', 'ivw_cate', 'ivw_rpca', 'ivw_gfa',
                         # 'robust', 'robust_cate', 'robust_rpca', 'robust_gfa', 
                         'susie', 'susie_cate', 'susie_rpca', 'susie_gfa'))
```

Here's the same plot, except with $\phi_{gz}=0.1$. This is a problem for RPCA,
but not Cate.

```{r cor_plei_gfa2, echo=FALSE, fig.width=12}
group_barchart('data/results_gfa_rpca2/cor_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls_oracle', 'ivw', 'ivw_cate', 'ivw_rpca', 'ivw_gfa',
                         # 'robust', 'robust_cate', 'robust_rpca', 'robust_gfa', 
                         'susie', 'susie_cate', 'susie_rpca', 'susie_gfa'))
```

Finally, here's a setting with $100$ SNPs (the above two have 300) and $\phi_{gx}=0.5$  and $\phi_{gy}=0.4$.

```{r cor_plei_gfa4, echo=FALSE, fig.width=12}
group_barchart('data/results_gfa_rpca4/cor_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls_oracle', 'ivw', 'ivw_cate', 'ivw_rpca', 'ivw_gfa',
                         # 'robust', 'robust_cate', 'robust_rpca', 'robust_gfa', 
                         'susie', 'susie_cate', 'susie_rpca', 'susie_gfa'))
```

Here's the same, but with both kinds of pleiotropy:

```{r both_plei_gfa4, echo=FALSE, fig.width=12}
group_barchart('data/results_gfa_rpca4/both_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls_oracle', 'ivw', 'ivw_cate', 'ivw_rpca', 'ivw_gfa',
                         # 'robust', 'robust_cate', 'robust_rpca', 'robust_gfa', 
                         'susie', 'susie_cate', 'susie_rpca', 'susie_gfa'))
```

Finally, here's the power at a fixed FPR threshold, using the same data as above:

```{r powfpr_both_plei_gfa4, echo=FALSE, fig.width=12}
power_fpr_thresh_plot('data/results_gfa_rpca4/both_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/', 
                      c('1','2','3','4'), prefix='all_res_', n_x_show = 4, thresh = 0.05,
               methods=c('2sls_oracle', 'ivw', 'ivw_cate', 'ivw_rpca', 'ivw_gfa',
                         # 'robust', 'robust_cate', 'robust_rpca', 'robust_gfa', 
                         'susie', 'susie_cate', 'susie_rpca', 'susie_gfa'))
```



## MR.Ash assessments

Last four plots above, but now comparing MR.Ash to other second-stage methods.

Correlated pleiotropy, $\phi_{gy}=0.1$.

```{r cor_plei_mrash2, echo=FALSE, fig.width=12}
group_barchart('data/results_mrash2/cor_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('ivw', 'robust', 'mrash', 'susie',
                 'ivw_gfa', 'robust_gfa', 'mrash_gfa', 'susie_gfa'))
```

Correlated pleiotropy, with $100$ SNPs (the above has 300) and $\phi_{gx}=0.5$  and $\phi_{gy}=0.4$.

```{r cor_plei_mrash4, echo=FALSE, fig.width=12}
group_barchart('data/results_mrash4/cor_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('ivw', 'robust', 'mrash', 'susie',
                 'ivw_gfa', 'robust_gfa', 'mrash_gfa', 'susie_gfa'))
```

Here's the same, but with both kinds of pleiotropy:

```{r both_plei_mrash4, echo=FALSE, fig.width=12}
group_barchart('data/results_mrash4/both_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('ivw', 'robust', 'mrash', 'susie',
                 'ivw_gfa', 'robust_gfa', 'mrash_gfa', 'susie_gfa'))
```

Finally, here's the power at a fixed FPR threshold, using the same data as above:

```{r powfpr_both_plei_mrash4, echo=FALSE, fig.width=12}
power_fpr_thresh_plot('data/results_mrash4/both_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/', 
                      c('1','2','3','4'), prefix='all_res_', n_x_show = 4, thresh = 0.05,
               methods=c('ivw', 'robust', 'mrash', 'susie',
                 'ivw_gfa', 'robust_gfa', 'mrash_gfa', 'susie_gfa'))
```




## Simulations with many exposures

We have talked about potentially supporting hundreds of exposures,
but thus far our simulations have only had 30. Here I raise that to 200.
First, we keep the other settings the same as above, with 300 SNPs.
Notably, there's still only four true causal exposures, so very sparse,
and also only three confounders.
Here's what it looks like with no pleiotropy:

```{r 200exp_300snp_no_plei, echo=FALSE, fig.width=12}
group_barchart('data/results_200exp_mrash_oracle/no_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('ivw', 'robust', 'mrash', 'susie',
                 'ivw_gfa', 'robust_gfa', 'mrash_gfa', 'susie_gfa'))
```

Right off the bat we notice something odd: robust is inflated despite no pleiotropy.
Everything else looks normal right now.

If we instead increase the number of SNPs to 1000, that goes away:

```{r 200exp_1000snp_no_plei, echo=FALSE, fig.width=12}
group_barchart('data/results_200exp_1000snp/no_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.2_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('ivw', 'robust', 'mrash', 'susie',
                 'ivw_gfa', 'robust_gfa', 'mrash_gfa', 'susie_gfa'))
```

Now here's correlated-only pleiotropy:

```{r 200exp_1000snp_cor_plei, echo=FALSE, fig.width=12}
group_barchart('data/results_200exp_1000snp/cor_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.2_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('ivw', 'robust', 'mrash', 'susie',
                 'ivw_gfa', 'robust_gfa', 'mrash_gfa', 'susie_gfa'))
```

Now we see another odd thing -- methods are not inflated even when they have no
first-stage factor analysis to infer confounders.

Finally, here's both kinds of pleiotropy:

```{r 200exp_1000snp_both_plei, echo=FALSE, fig.width=12}
group_barchart('data/results_200exp_1000snp/both_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.2_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('ivw', 'robust', 'mrash', 'susie',
                 'ivw_gfa', 'robust_gfa', 'mrash_gfa', 'susie_gfa'))
```

As usual, IVW and Robust drop in power, so methods like MR.Ash and Susie perform
relatively better here.

I ran some additional experiments (not shown here) which showed that the lack
of inflation under pleiotropy was due to a low number of confounders relative to
the number of exposures.

So the interesting result is that two ratios are important:

* The "M/K" or "num SNPs / num exposures" ratio -- if <1 than traditional methods
   don't work at all, and robust becomes inflated if it's close to 1.
* The "J/K" or "num confounders / num exposures" ratio -- if very low (e.g. 1/100)
   then confounding will not inflate methods, even if Zs affect many Xs.
   It is possible this can be overrided with very powerful confounding effects.



## Simulations using UK Biobank Genotypes

Here are some simulations using real genotypes from White European samples in
the UK Biobank.
Phenotype simulations is still the same as above -- we just use real genotypes
instead of simulating them.
We randomly downsample samples, SNPs, and loci from the mvSusie blood cell trait 
data, which contains 975 loci averaging ~10k SNPs each and ~250k samples.
We usually use 100 loci, 1000 SNPs per locus, and 10-20k samples.

In addition to using real genoytpes, we make these simulations more realistic in
another important dimension: SNP selection.
Instead of providing the true causal SNPs to the methods as in the above 
simulations, we perform SNP selection with mvSusie, using the genotypes and 
simulated phenotypes as input.


Here are the settings used for these simlations:

* 10,000 samples
* 100 loci, each with 1-5 causal SNPs implanted (so ~300 overall)
* 30 exposures, 3 confounders
* $\theta_{gx}=0.2$, $\theta_{gz}=0.4$, $\theta_{zx}=0.5$, $\theta_{zy}=0.375$
* $\phi_{gx}=0.05$, $\phi_{gy}=0.05$, $\phi_{gz}=0.05$, $\phi_{zx}=0.5$
* As usual, first four exposures are true effects with effect sizes $0.05,0.1,0.2,0.3$

Here are the results with correlated pleiotropy:

```{r cor_plei_ukbb_mvsusie, echo=FALSE, fig.width=12}
group_barchart('data/results_ukbb_mvsusie/cor_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.2_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('ivw', 'robust', 'susie',
                 'ivw_gfa', 'robust_gfa', 'susie_gfa'))
```

And here are the results with both kinds of pleiotropy:

```{r both_plei_ukbb_mvsusie, echo=FALSE, fig.width=12}
group_barchart('data/results_ukbb_mvsusie/both_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.2_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('ivw', 'robust', 'susie',
                 'ivw_gfa', 'robust_gfa', 'susie_gfa'))
```




## SNP Selection Comparison

How should we select SNPs to use as instruments?
The traditional strategy is to pick the SNP with the lowest p-value in each locus.
But this becomes tricky in the multi-exposure case.
What if a locus has different causal variants for different traits?

To test this, I compared several SNP selection strategies in the UK Biobank simulations:

* mvSusie, i.e. the same strategy as above
* mvSusie-RSS, the summary statistics mode of mvSusie
* max: select the SNP at each locus that has the best z-score for any trait
* mean: select the SNP at each locus that has the best z-score, averaged across
all traits

The latter three methods use summary statistics, which would normally take an
intractable amount of time to generate.
So instead I simulated the statistics from the RSS model,

$$\hat{\beta} \sim \mathcal{N}(SRS\beta^{-1},SRS)$$

where the true $\beta$ are the effects simulated by my phenotype simulator, the
$R$ is taken from the LD file included with each mvSusie locus, and $S$ is
a matrix containing SNP standard deviations (see RSS paper).
The standard errors for the summary statistics were simply set to $1/\sqrt{N}$.

We can show that using mvSusie or mvSusie-RSS leads to a better F1 score for
SNP selection, as well as improved downstream performance.

First, here is the precision / recall / F1 for each method (no pleiotropy):

* mvSusie: 0.34358 / 0.47136 / 0.39688
* mvSusie-RSS: 0.47689 / 0.48672 / 0.47989
* max: 0.63289 / 0.2106 / 0.31591
* mean: 0.42589 / 0.14216 / 0.21308

Results look similar regardless of the level of pleiotropy.
There is a clear hierarchy, mvSusie-RSS > mvSusie > max > mean, in terms of F1.
The high precision but low recall of max/mean reflects that they can't capture
all causal SNPs at each locus.
It's a bit less clear why mvSusie-RSS > mvSusie, but it's probably because I 
simulated the sumstats exactly from the RSS model.

The next question, naturally, is whether this actually impacts downstream
results of the methods.
The answer is yes, and here's a graph showing it for IVW and Susie (no pleiotropy):

```{r no_plei_selection, echo=FALSE, fig.width=12}
group_barchart('data/results_ukbb_selection_comp/no_plei/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('ivw_gfa_mvsusie', 'ivw_gfa_mvsusie_rss', 'ivw_gfa_max',
                 'ivw_gfa_mean', 'susie_gfa_mvsusie', 'susie_gfa_mvsusie_rss',
                 'susie_gfa_max', 'susie_gfa_mean'))
```




## Sims with true genotypes and exposures, only simulating outcome

In these simulations, we use true UK Biobank genotypes, as above, but here we
also use true exposure phenotype values. We only simulate the outcome trait.
Simulating the confounders is optional, but here I used real confounders too.
This makes the simulation as "realistic" as possible, with the downside being 
that we don't know which SNPs truly affect the exposures & can't control those
effects.

Here I used loci for 16 UK Biobank blood cell traits preprocessed for the mvSusie paper. 
I downsampled to 50,000 samples and 200 loci for simplicity.
Out of the 16 traits, I picked two randomly to serve as unobserved confounders.

Here are the results with no pleiotropy. Methods are calibrated, as expected.

```{r no_plei_truegx, echo=FALSE, fig.width=12}
group_barchart('data/results_true_gx/no_plei_gy_0.2_zx_0.2_zy_0.2/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls', '2sls_gfa', 'ivw', 'ivw_gfa', 
                         'robust', 'robust_gfa', 'susie', 'susie_gfa'))
```

Now here are the results with correlated pleiotropy, with 
$\gamma_{zx} = \gamma_{zy} = 0.2$. 
Remember, I don't have control over $\gamma_{gz}$, since here $Z$ are real traits.
Here we see a great deal of confounding, even with GFA:

```{r cor_plei_truegx, echo=FALSE, fig.width=12}
group_barchart('data/results_true_gx/cor_plei_gy_0.2_zx_0.2_zy_0.2/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('2sls', '2sls_gfa', 'ivw', 'ivw_gfa', 
                         'robust', 'robust_gfa', 'susie', 'susie_gfa'))
```

So we are getting results that seem plausible, but the confounding seems quite strong.
I ran more sims with $\gamma_{zx} = \gamma_{zy} = 0.1$ (not shown), which slightly
reduced confounding, but methods were still inflated even with GFA.
Still need to figure out what's going on here.




# Real data results

I ran 2SLS/IVW/Robust/Susie/MR.Ash + nothing/GFA/RPCA on the 
loci for 16 UK Biobank blood cell traits preprocessed for the mvSusie paper.
I chose Hemoglobin as the outcome and the other 15 as exposures, arbitrarily.
I have no idea if this is reasonable, so take the second-stage results with a
grain of salt. 
I'll update with more realistic traits and better formatting later.

Here are the number of significant traits found by each method:

* 2SLS: 10
* 2SLS-GFA: 10
* 2SLS-RPCA: 9
* IVW: 10
* IVW-GFA: 7
* IVW-RPCA: 8
* Robust: 7
* Robust-GFA: 6
* Robust-RPCA: 8
* Susie: 3
* Susie-GFA: 4 
* Susie-RPCA: 4
* MR.Ash: 6
* MR.Ash-GFA: 6
* MR.Ash-RPCA: 6

So we can see that sometimes first-stage methods reduce the number of significant
trait pairs. 
The methods vary on the number of exposures found significant, though they
generally agree on the order.


Here are the number of factors found by each FA method, and their correlations
with the 15 exposure traits (sorry for ugly raw format):

* GFA: 4 factors (after pruning heuristic)

```
[1] "Number of factors detected by GFA: 4"
[1] "Correlations with x_betas:"
        WBC_count   RBC_count        MCV         RDW Platelet_count
[1,] -0.001640976 -0.75468968 0.98605224 -0.31663391     0.03624346
[2,]  0.325981371 -0.09764243 0.05087593 -0.05687534     0.93476251
[3,]  0.023064779 -0.07617768 0.12559695 -0.15648708     0.01058407
[4,] -0.321576727 -0.02835313 0.05563161 -0.00118629     0.03691328
     Plateletcrit         PDW Lymphocyte_perc Monocyte_perc Neutrophill_perc
[1,]   0.04016506 -0.06180007      0.06647548    0.05594493      -0.06597634
[2,]   0.90809002 -0.55897034      0.01045073    0.01053307      -0.03457303
[3,]   0.02770390  0.10704047     -0.06414842   -0.03178419       0.07043654
[4,]   0.00682206 -0.05983110      0.96675776    0.27570438      -0.97842300
     Eosinophill_perc Basophill_perc Reticulocyte_perc        MSCV     HLR_perc
[1,]      -0.06279681     0.02657169       0.102809344  0.88625102  0.170774450
[2,]       0.09842009     0.05558868      -0.008599868  0.03262786  0.007867302
[3,]      -0.01165736    -0.00792867       0.987386457 -0.14451179  0.987802241
[4,]       0.20059308     0.11994296      -0.082500786  0.12663053 -0.061190626
```


* RPCA: 13 factors (no pruning)

```
[1] "Number of factors detected by RPCA: 13"
[1] "Correlations with x_betas:"
         WBC_count    RBC_count          MCV          RDW Platelet_count
 [1,] -0.102095006  0.462869586 -0.479733770  0.024229052   -0.372475422
 [2,]  0.419429298  0.284659704 -0.396475049  0.104518434    0.606220257
 [3,] -0.295600205  0.368873285 -0.420897576  0.171037432   -0.087991929
 [4,]  0.079700065 -0.049654160  0.070989330  0.089435198   -0.121957750
 [5,] -0.013486931  0.072250670  0.035881308  0.053908895   -0.059051433
 [6,] -0.408498335 -0.238159343  0.007617194 -0.380541389    0.103350258
 [7,] -0.232778402 -0.173081414 -0.056831128  0.308649364   -0.035678286
 [8,]  0.090406415 -0.126642244  0.042541912 -0.083316360   -0.001085696
 [9,] -0.059653731 -0.011806263 -0.052414418  0.270085345   -0.023874378
[10,]  0.014354183 -0.002924474  0.020023040  0.008973424    0.018205410
[11,]  0.010207131 -0.017109076  0.037672692 -0.010542113    0.013850411
[12,] -0.019022972  0.004579979  0.005743584  0.007400343    0.003209279
[13,]  0.004254445  0.008882500  0.010584905 -0.010955323    0.010688070
      Plateletcrit          PDW Lymphocyte_perc Monocyte_perc Neutrophill_perc
 [1,] -0.352704986  0.364713774    -0.361376169  -0.191987718      0.403521073
 [2,]  0.641283437 -0.285581415    -0.249106479  -0.060101095      0.224404739
 [3,] -0.147663273 -0.017198872     0.433218044   0.194557047     -0.493851833
 [4,] -0.135894160 -0.023659701    -0.444764748  -0.160943509      0.474331214
 [5,]  0.010917763  0.049580935    -0.269549980   0.442772389      0.001697879
 [6,] -0.032898149 -0.179395399    -0.056383699   0.029950428      0.042152127
 [7,]  0.093138535  0.206575311    -0.030301279   0.032833525      0.042485129
 [8,]  0.091555474  0.169117602    -0.036891945  -0.185170321     -0.007131183
 [9,] -0.074433455 -0.156936780    -0.018031752  -0.116356819      0.017082797
[10,]  0.015548812 -0.032775914    -0.003521535  -0.050230055      0.017867336
[11,]  0.004391547 -0.013130119    -0.008541238   0.037531366     -0.002805021
[12,] -0.007191359  0.009035615    -0.001589169  -0.006344848      0.004468541
[13,]  0.016166542  0.014291370    -0.005441077  -0.010111899      0.012487903
      Eosinophill_perc Basophill_perc Reticulocyte_perc         MSCV
 [1,]     -0.088915000   -0.117998027      0.2474364500 -0.601589489
 [2,]      0.059826493    0.012290744     -0.0962091162 -0.327354648
 [3,]      0.220223819    0.116363603     -0.4617865613 -0.226336510
 [4,]     -0.157427805   -0.069499723     -0.4847973241  0.187549039
 [5,]      0.335569245    0.168349777      0.0611062173  0.062306447
 [6,]     -0.016342239   -0.019982891      0.0658507416 -0.142766188
 [7,]     -0.154073560    0.193978437      0.0126234349  0.016055167
 [8,]      0.423262465    0.301601724     -0.0054947977 -0.005286929
 [9,]      0.210416415   -0.253647386      0.0003153864  0.003298467
[10,]      0.009229434    0.002925570      0.0661240105  0.001889833
[11,]     -0.001062457   -0.041301685      0.0623734135  0.001506438
[12,]     -0.005449317   -0.007815489      0.0123083211  0.002891452
[13,]     -0.013552033   -0.046556558      0.0173652680 -0.014306854
         HLR_perc
 [1,]  0.17455981
 [2,] -0.10057817
 [3,] -0.47560346
 [4,] -0.48563753
 [5,]  0.06599330
 [6,]  0.02873132
 [7,]  0.02948258
 [8,] -0.01456019
 [9,]  0.02461489
[10,]  0.06070806
[11,]  0.05783540
[12,]  0.01099033
[13,]  0.00724240
```




## Population stratification assessments

Simulated population structure using Balding-Nichols model on two populations.
$F_{ST}=0.1$, $\gamma_{psx}=0.25$, $\gamma_{psy}=0.25$, $\gamma_{psz}=0.25$.

No pleiotropy (just population stratification):

```{r no_plei_ps2, echo=FALSE, fig.width=12}
group_barchart('data/results_ps2/no_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('ivw', 'robust', 'mrash', 'susie',
                 'ivw_cate', 'robust_cate', 'mrash_cate', 'susie_cate',
                 'ivw_gfa', 'robust_gfa', 'mrash_gfa', 'susie_gfa'))
```

Both types of pleiotropy:

```{r both_plei_ps2, echo=FALSE, fig.width=12}
group_barchart('data/results_ps2/both_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('ivw', 'robust', 'mrash', 'susie',
                 'ivw_cate', 'robust_cate', 'mrash_cate', 'susie_cate',
                 'ivw_gfa', 'robust_gfa', 'mrash_gfa', 'susie_gfa'))
```

Here's the power at a fixed FPR threshold, with no pleiotropy:

```{r powfpr_no_plei_ps2, echo=FALSE, fig.width=12}
power_fpr_thresh_plot('data/results_ps2/no_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/', 
                      c('1','2','3','4'), prefix='all_res_', n_x_show = 4, thresh = 0.05,
               methods=c('ivw', 'robust', 'mrash', 'susie',
                 'ivw_cate', 'robust_cate', 'mrash_cate', 'susie_cate',
                 'ivw_gfa', 'robust_gfa', 'mrash_gfa', 'susie_gfa'))
```

No pleiotropy (just population stratification), tougher setting:

```{r no_plei_ps4, echo=FALSE, fig.width=12}
group_barchart('data/results_ps4/no_plei_gx_0.2_gy_0.2_gz_0.4_psix_0.1_psiy_0.15_mu_0.0/',
               prefix='all_res_', n_x_show = 8, thresh = 0.05,
               methods=c('ivw', 'robust', 'mrash', 'susie',
                 'ivw_cate', 'robust_cate', 'mrash_cate', 'susie_cate',
                 'ivw_gfa', 'robust_gfa', 'mrash_gfa', 'susie_gfa'))
```
